include required(classpath("application.conf"))
include "build_application.inc.conf"
include "gcp_batch_application.inc.conf"

services {
  HealthMonitor.config {
    check-gcpbatch-backends: [
      "GCPBATCH",
    ]
  }
}

backend {
  default = "GCPBATCH"
  enabled = ["GCPBATCH", "GCPBATCH-Virtual-Private-Cloud-Labels", "GCPBATCH-Virtual-Private-Cloud-Literals"]
  providers {
    # Default gcp batch backend
    GCPBATCH {
      actor-factory = "cromwell.backend.google.batch.GcpBatchBackendLifecycleActorFactory"
      config {
        # When importing: Remember to also include an appropriate provider_config.inc.conf here.

        # TODO: Should not need because already included.  testing.
        include "gcp_batch_provider_config.inc.conf"

        include "dockerhub_provider_config_v2.inc.conf"
        # This SA does not have permission to bill this project when accessing RP buckets.
        # This is on purpose so that we can assert the failure (see requester_pays_localization_negative)
        batch.compute-service-account = "centaur@broad-dsde-cromwell-dev.iam.gserviceaccount.com"
        filesystems.http {}
      }
    }
    GCPBATCH-Virtual-Private-Cloud-Labels {
      actor-factory = "REPLACEME!"
      config {
        # When importing: Remember to also include an appropriate provider_config.inc.conf here.

        genomics.compute-service-account = "centaur@broad-dsde-cromwell-dev.iam.gserviceaccount.com"
        filesystems.http {}
        virtual-private-cloud {
          network-label-key = "cromwell-ci-gcpbatch-network"
          subnetwork-label-key = "cromwell-ci-gcpbatch-subnetwork"
          auth = "service_account"
        }

        # Have the engine authenticate to docker.io. See BT-141 for more info.
        include "dockerhub_provider_config_v2.inc.conf"
      }
    }
    GCPBATCH-Virtual-Private-Cloud-Literals {
      actor-factory = "REPLACEME!"
      config {
        # When importing: Remember to also include an appropriate provider_config.inc.conf here.

        genomics.compute-service-account = "centaur@broad-dsde-cromwell-dev.iam.gserviceaccount.com"
        filesystems.http {}
        virtual-private-cloud {
          # integration testing:
          #  - fully qualified name
          #  - hardcoded project id
          #  - does not end with `/`
          network-name = "projects/broad-dsde-cromwell-dev/global/networks/cromwell-ci-gcpbatch-vpc-network"
          # integration testing:
          #  - fully qualified name
          #  - cromwell replaces the `${projectId}`
          #  - papi replaces the `*`
          # Btw, yes, each of the subnets in this network have the same name as the network itself
          # https://console.cloud.google.com/networking/networks/details/cromwell-ci-vpc-network?project=broad-dsde-cromwell-dev&pageTab=SUBNETS

          # subnetwork-name = "projects/${projectId}/regions/*/subnetworks/cromwell-ci-gcpbatch-vpc-network"
          # The '*' wildcard as used in PAPI v2 throws this error:
          # io.grpc.StatusRuntimeException: INVALID_ARGUMENT: subnetwork field is invalid. subnetwork: projects/broad-dsde-cromwell-dev/regions/*/subnetworks/cromwell-ci-gcpbatch-vpc-network is not matching the expected format: regions/([a-z0-9-_]+)/subnetworks/([a-z]([-a-z0-9]*[a-z0-9])?)$
          #
          # Hardcoding to us-central1 passes regex validation but ultimately fails with this error:
          # Job gets no longer retryable information Batch Error: code - CODE_GCE_BAD_REQUEST, description - googleapi: Error 400: Invalid value for field 'region': 'us-central1'. Unknown region., invalid, already retried 3 times, errors record CODE_GCE_BAD_REQUEST.
          subnetwork-name = "projects/${projectId}/regions/us-central1/subnetworks/cromwell-ci-gcpbatch-vpc-network"
        }

        # Have the engine authenticate to docker.io. See BT-141 for more info.
        include "dockerhub_provider_config_v2.inc.conf"
      }
    }
  }
}
