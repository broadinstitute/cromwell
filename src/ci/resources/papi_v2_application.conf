include required(classpath("application.conf"))
include "build_application.inc.conf"
include "papi_application.inc.conf"

services {
  MetadataService {
    class = "cromwell.services.metadata.hybridcarbonite.HybridMetadataServiceActor"
    config {
      # This section may also contain the same set of options as would be present in the 'config' section of the
      # default (cromwell.services.metadata.impl.MetadataServiceActor) config

      # The carbonite section contains carbonite-specific options
      carbonite-metadata-service {
        # enable carboniting
        enabled = true

        # To help us stay below the Travis "max log size" value:
        debug-logging = false

        # Which bucket to use for storing the generated metadata JSON
        bucket = "carbonite-test-bucket"

        # A filesytem able to access the specified bucket:
        filesystems {
          gcs {
            # A reference to the auth to use for storing and retrieving metadata:
            auth = "service_account"
          }
        }
      }
    }
  }

  HealthMonitor.config.check-papi-backends: [
    "Papi",
    "Papiv2",
    "Papiv2USADockerhub",
    "Papiv2NoDockerHubConfig",
    "Papiv2RequesterPays",
    "Papi-Caching-No-Copy",
    "Papiv2-Virtual-Private-Cloud",
    "Papiv2-Retry-With-More-Memory",
  ]
}

backend {
  default = "Papi"
  enabled = ["Papi", "Papiv2", "Papi-Caching-No-Copy", "Papiv2RequesterPays"]
  providers {
    # Default papi v2 backend
    Papi {
      actor-factory = "cromwell.backend.google.pipelines.v2alpha1.PipelinesApiLifecycleActorFactory"
      config {
        include "papi_provider_config.inc.conf"
        include "dockerhub_provider_config_v2.inc.conf"
        # This SA does not have permission to bill this project when accessing RP buckets.
        # This is on purpose so that we can assert the failure (see requester_pays_localization_negative)
        genomics.compute-service-account = "centaur@broad-dsde-cromwell-dev.iam.gserviceaccount.com"
        filesystems.http {}
      }
    }
    # Same as Papi, but with a v2 specific name so it can be targeted in centaur tests
    Papiv2 {
      actor-factory = "cromwell.backend.google.pipelines.v2alpha1.PipelinesApiLifecycleActorFactory"
      config {
        include "papi_provider_config.inc.conf"
        include "dockerhub_provider_config_v2.inc.conf"
        # This SA does not have permission to bill this project when accessing RP buckets.
        # This is on purpose so that we can assert the failure (see requester_pays_localization_negative)
        genomics.compute-service-account = "centaur@broad-dsde-cromwell-dev.iam.gserviceaccount.com"
        filesystems.http {}
        name-for-call-caching-purposes = "Papi"
      }
    }
    # Same as Papi but specifying `user_service_account` auth in config.
    Papiv2USADockerhub {
      actor-factory = "cromwell.backend.google.pipelines.v2alpha1.PipelinesApiLifecycleActorFactory"
      config {
        include "papi_provider_config.inc.conf"
        include "dockerhub_provider_config_v2_usa.inc.conf"
        # This SA does not have permission to bill this project when accessing RP buckets.
        # This is on purpose so that we can assert the failure (see requester_pays_localization_negative)
        genomics.compute-service-account = "centaur@broad-dsde-cromwell-dev.iam.gserviceaccount.com"
        filesystems.http {}
        name-for-call-caching-purposes = "Papi"
      }
    }
    # Same as Papiv2 but with no Docker Hub configuration so access to private Docker Hub images will
    # require correct handling of workflow options.
    Papiv2NoDockerHubConfig {
      actor-factory = "cromwell.backend.google.pipelines.v2alpha1.PipelinesApiLifecycleActorFactory"
      config {
        include "papi_provider_config.inc.conf"
        # This SA does not have permission to bill this project when accessing RP buckets.
        # This is on purpose so that we can assert the failure (see requester_pays_localization_negative)
        genomics.compute-service-account = "centaur@broad-dsde-cromwell-dev.iam.gserviceaccount.com"
        filesystems.http {}
      }
    }
    Papiv2RequesterPays {
      actor-factory = "cromwell.backend.google.pipelines.v2alpha1.PipelinesApiLifecycleActorFactory"
      config {
        include "papi_provider_config.inc.conf"
        include "dockerhub_provider_config_v2.inc.conf"
        filesystems.gcs.auth = "requester_pays_service_account"
        genomics.compute-service-account = "requester-pays-authorized@broad-dsde-cromwell-dev.iam.gserviceaccount.com"
        filesystems.http {}
      }
    }
    Papi-Caching-No-Copy {
      actor-factory = "cromwell.backend.google.pipelines.v2alpha1.PipelinesApiLifecycleActorFactory"
      config {
        include "papi_provider_config.inc.conf"
        filesystems.gcs.caching.duplication-strategy = "reference"
        filesystems.http {}
      }
    }
    Papiv2-Virtual-Private-Cloud {
      actor-factory = "cromwell.backend.google.pipelines.v2alpha1.PipelinesApiLifecycleActorFactory"
      config {
        include "papi_provider_config.inc.conf"
        genomics.compute-service-account = "centaur@broad-dsde-cromwell-dev.iam.gserviceaccount.com"
        filesystems.http {}
        virtual-private-cloud {
          network-label-key = "cromwell-ci-network"
          subnetwork-label-key = "cromwell-ci-subnetwork"
          auth = "service_account"
        }
      }
    }
    papi-v2-gcsa {
      actor-factory = "cromwell.backend.google.pipelines.v2alpha1.PipelinesApiLifecycleActorFactory"
      config {
        include "papi_provider_config.inc.conf"
        project = "user_error: google_project must be set in workflow options http://cromwell.readthedocs.io/en/develop/wf_options/Google/"
        root = "user_error: jes_gcs_root must be set in workflow options http://cromwell.readthedocs.io/en/develop/wf_options/Google/"
        genomics.compute-service-account = "user_error: google_compute_service_account must be set in workflow options http://cromwell.readthedocs.io/en/develop/wf_options/Google/"
        genomics.auth = "google_compute_service_account"
        filesystems.http {}
        filesystems.drs.auth = "user_service_account"
        filesystems.gcs.auth = "user_service_account"
        filesystems.gcs.project = "user_error: user_service_account must be set in workflow options http://cromwell.readthedocs.io/en/develop/wf_options/Google/"
      }
    }
    papi-v2-usa {
      actor-factory = "cromwell.backend.google.pipelines.v2alpha1.PipelinesApiLifecycleActorFactory"
      config {
        include "papi_provider_config.inc.conf"
        filesystems.http {}
        filesystems.gcs.auth = "user_service_account"
        filesystems.drs.auth = "user_service_account"
        project = "user_error: google_project must be set in workflow options http://cromwell.readthedocs.io/en/develop/wf_options/Google/"
        root = "user_error: jes_gcs_root must be set in workflow options http://cromwell.readthedocs.io/en/develop/wf_options/Google/"
      }
    }
    Papiv2-Retry-With-More-Memory {
      actor-factory = "cromwell.backend.google.pipelines.v2alpha1.PipelinesApiLifecycleActorFactory"
      config {
        include "papi_provider_config.inc.conf"
        genomics.compute-service-account = "centaur@broad-dsde-cromwell-dev.iam.gserviceaccount.com"
        filesystems.http {}
        memory-retry {
          error-keys = ["OutOfMemoryError"]
          multiplier = 1.1
        }
      }
    }
    # Same as Papi but with GCS parallel composite uploads turned on.
    Papiv2ParallelCompositeUploads {
      actor-factory = "cromwell.backend.google.pipelines.v2alpha1.PipelinesApiLifecycleActorFactory"
      config {
        include "papi_provider_config.inc.conf"
        include "dockerhub_provider_config_v2.inc.conf"
        # This SA does not have permission to bill this project when accessing RP buckets.
        # This is on purpose so that we can assert the failure (see requester_pays_localization_negative)
        genomics.compute-service-account = "centaur@broad-dsde-cromwell-dev.iam.gserviceaccount.com"
        # Files larger than 150M should be delocalized using parallel composite uploading.
        genomics.parallel-composite-upload-threshold = 150M
        filesystems.http {}
        name-for-call-caching-purposes = "Papi"
      }
    }
  }
}
