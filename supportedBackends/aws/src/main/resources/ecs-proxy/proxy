#!/bin/bash
# Copyright 2018 Amazon.com, Inc. or its affiliates.
#
#  Redistribution and use in source and binary forms, with or without
#  modification, are permitted provided that the following conditions are met:
#
#  1. Redistributions of source code must retain the above copyright notice,
#  this list of conditions and the following disclaimer.
#
#  2. Redistributions in binary form must reproduce the above copyright
#  notice, this list of conditions and the following disclaimer in the
#  documentation and/or other materials provided with the distribution.
#
#  3. Neither the name of the copyright holder nor the names of its
#  contributors may be used to endorse or promote products derived from
#  this software without specific prior written permission.
#
#  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
#  "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING,
#  BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND
#  FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL
#  THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT,
#  INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
#  (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
#  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
#  HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,
#  STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING
#  IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
#  POSSIBILITY OF SUCH DAMAGE.

# We expect the following environment variables:
#
# AWS_CROMWELL_TASK_DOCKER_ID
# AWS_CROMWELL_RC_FILE
# AWS_CROMWELL_PATH
# AWS_CROMWELL_LOCAL_DISK
# AWS_CROMWELL_CALL_ROOT

# These variables are optional but may be available
# AWS_CROMWELL_INPUTS
# AWS_CROMWELL_OUTPUTS


awscp() {
  initExitCode=1
  retryTimes=0
  while [ $initExitCode -ne 0 ]
  do
    echo "aws s3 $1 --sse AES256 --no-progress $2 $3"
    aws s3 "$1" --sse AES256 --no-progress "$2" "$3"
    initExitCode=$?
    if [ $initExitCode -ne 0 ]; then
      if [ $retryTimes -gt 4 ]; then
        echo "Have tried 5 more times. Will exit ..."
        exit 1
      fi
      echo "Copying failed. Wait for 60 secs and try again ..."
      sleep 60
      retryTimes=$((retryTimes+1))
    fi
  done
}

copyfile() {
  IFS="," read -r -a components <<< "$1"
  name=${components[0]}
  s3location=${components[1]}
  localname=${components[2]}
  mountpoint=${components[3]}
  IFS=" " read -r -a mountpointcomponents <<< "$mountpoint"
  mountname=${mountpointcomponents[0]}
  localdirectory=${mountpointcomponents[1]}

  # Name is not relevant here
  echo "name=$name"

  # S3 location to which this needs to be copied
  echo "s3location=$s3location"

  # Source: This is within the localdirectory
  echo "localname=$localname"

  # Mountpoint: This is an aggregate and we shall ignore
  # echo "mountpoint=$mountpoint"

  # Mountname: This is only valid on the host
  echo "mountname=$mountname"

  # Local (within container) directory. Needed in conjuntion with source
  echo "localdirectory=$localdirectory"

  if [ "$2" == "out" ]; then
    # Globbed outputs are in a specially-named directory
    if [[ "$localname" == glob-*/"*" ]]; then
      awscp sync "${localdirectory}/${name}" "${s3location}"
    else
      localfilepath="${localdirectory}/${localname}"
      if [ -e  "$localfilepath" ] ; then
        awscp cp "${localfilepath}" "${s3location}"
      else
        echo "No such local file: ${localfilepath}"
        exit 1
      fi
    fi
  else
    awscp cp "${s3location}" "${localdirectory}/${localname}"
  fi
}

copyfiles() {
  IFS=";" read -r -a files <<< "$1"
  for file in "${files[@]}"; do
    echo "File: $file"
    copyfile "$file" "$2"
  done
}

copyToS3() {
  if [ -n "${1}" ]; then
    awscp cp "${1}" "${2}"
  else
    echo "Variable defining file to be copied does not exist"
  fi
}

decompVal() {
  echo "$1" | base64 -d | zcat
}
###########################################################################
# The general plan is to copy all inputs from S3 to the container
# We share the same volumes/mount points of the original, so we can go to
# town here.
#
# Once copied, we can run the container and let it finish. Then we'll
# copy outputs as necessary
#
###########################################################################
if [ -n "${AWS_CROMWELL_INPUTS}" ]; then
  echo "Copying input files from s3"
  copyfiles "${AWS_CROMWELL_INPUTS}" in
fi

if [ -n "${AWS_CROMWELL_INPUTS_GZ}" ]; then
  echo "Copying input files from s3 (gzipped input)"
  inputs=$(decompVal "${AWS_CROMWELL_INPUTS_GZ}")
  copyfiles "${inputs}" in
fi

# -i will attach stdin, which effectively makes this a blocking call
# we redirect to /dev/null so as not to pollute the logs
docker start -i "${AWS_ECS_PROXY_TARGET_CONTAINER_ID}" > /dev/null
rc=$?

echo "Copying rc file"
copyToS3 "${AWS_CROMWELL_RC_FILE}" "${AWS_CROMWELL_CALL_ROOT}/"
echo "Copying stdout file"
copyToS3 "${AWS_CROMWELL_STDOUT_FILE}" "${AWS_CROMWELL_CALL_ROOT}/"
echo "Copying stderr file"
copyToS3 "${AWS_CROMWELL_STDERR_FILE}" "${AWS_CROMWELL_CALL_ROOT}/"

# Wait until copying stdout/stderr/rc before copying outputs to ensure they're always there in case of
# transfer error. Check first that there are outputs prior to trying to copy the outputs
if [ -n "${AWS_CROMWELL_OUTPUTS}" ]; then
  echo "Copying output files to S3"
  copyfiles "${AWS_CROMWELL_OUTPUTS}" out
fi

echo "Removing target container"
docker rm "${AWS_ECS_PROXY_TARGET_CONTAINER_ID}"

echo "Done - exiting"
exit $rc
