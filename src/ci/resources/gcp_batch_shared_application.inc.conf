include required(classpath("application.conf"))
include "build_application.inc.conf"
include "gcp_batch_application.inc.conf"

services {
  HealthMonitor.config {
    check-gcpbatch-backends: [
      "GCPBATCH",
    ]
  }
}

backend {
  default = "GCPBATCH"
  enabled = ["GCPBATCH", "GCPBATCH-Virtual-Private-Cloud-Labels", "GCPBATCH-Virtual-Private-Cloud-Literals"]
  providers {
    # Default gcp batch backend
    GCPBATCH {
      actor-factory = "cromwell.backend.google.batch.GcpBatchBackendLifecycleActorFactory"
      config {
        # When importing: Remember to also include an appropriate provider_config.inc.conf here.

        # TODO: Should not need because already included.  testing.
        include "gcp_batch_provider_config.inc.conf"

        include "dockerhub_provider_config_v2.inc.conf"
        # This SA does not have permission to bill this project when accessing RP buckets.
        # This is on purpose so that we can assert the failure (see requester_pays_localization_negative)
        batch.compute-service-account = "centaur@broad-dsde-cromwell-dev.iam.gserviceaccount.com"
        filesystems.http {}
      }
    }
    GCPBATCH-Virtual-Private-Cloud-Labels {
      actor-factory = "REPLACEME!"
      config {
        # When importing: Remember to also include an appropriate provider_config.inc.conf here.

        genomics.compute-service-account = "centaur@broad-dsde-cromwell-dev.iam.gserviceaccount.com"
        filesystems.http {}
        virtual-private-cloud {
          network-label-key = "cromwell-ci-gcpbatch-network"
          subnetwork-label-key = "cromwell-ci-gcpbatch-subnetwork"
          auth = "service_account"
        }

        # Have the engine authenticate to docker.io. See BT-141 for more info.
        include "dockerhub_provider_config_v2.inc.conf"
      }
    }
    GCPBATCH-Virtual-Private-Cloud-Literals {
      actor-factory = "REPLACEME!"
      config {
        # When importing: Remember to also include an appropriate provider_config.inc.conf here.

        genomics.compute-service-account = "centaur@broad-dsde-cromwell-dev.iam.gserviceaccount.com"
        filesystems.http {}
        virtual-private-cloud {
          # integration testing:
          #  - fully qualified name
          #  - hardcoded project id
          #  - does not end with `/`
          network-name = "projects/broad-dsde-cromwell-dev/global/networks/cromwell-ci-gcpbatch-vpc-network"
          # integration testing:
          #  - fully qualified name
          #  - cromwell replaces the `${projectId}`
          #  - papi replaces the `*`
          # Btw, yes, each of the subnets in this network have the same name as the network itself
          # https://console.cloud.google.com/networking/networks/details/cromwell-ci-vpc-network?project=broad-dsde-cromwell-dev&pageTab=SUBNETS

          # subnetwork-name = "projects/${projectId}/regions/*/subnetworks/cromwell-ci-gcpbatch-vpc-network"
          # The '*' wildcard as used in PAPI v2 throws this error:
          # io.grpc.StatusRuntimeException: INVALID_ARGUMENT: subnetwork field is invalid. subnetwork: projects/broad-dsde-cromwell-dev/regions/*/subnetworks/cromwell-ci-gcpbatch-vpc-network is not matching the expected format: regions/([a-z0-9-_]+)/subnetworks/([a-z]([-a-z0-9]*[a-z0-9])?)$
          #
          # NOTE: the region specified for the subnet must match the `zone` the task will run in, which may not match the `zone` of the GCP Batch job.
          # e.g. in Centaur GCP Batch jobs are sent to `us-central1`, but the `wf_zone.options` file species a `zone` of `us-east1-c` explicitly.`
          subnetwork-name = "projects/broad-dsde-cromwell-dev/regions/us-east1/subnetworks/cromwell-ci-gcpbatch-vpc-network"
        }

        # Have the engine authenticate to docker.io. See BT-141 for more info.
        include "dockerhub_provider_config_v2.inc.conf"
      }
    }
  }
}
