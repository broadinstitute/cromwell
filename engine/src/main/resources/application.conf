
webservice {
  port = 8000
  interface = 0.0.0.0
  instance.name = "reference"
}

akka {
  loggers = ["akka.event.slf4j.Slf4jLogger"]
  actor {
    default-dispatcher {
      fork-join-executor {
        # Number of threads = min(parallelism-factor * cpus, parallelism-max)
        # Below are the default values set by Akka, uncomment to tune these

        #parallelism-factor = 3.0
        #parallelism-max = 64
      }
    }
  }
}

spray.can {
  server {
    request-timeout = 40s
  }
  client {
    request-timeout = 40s
    connecting-timeout = 40s
  }
}

workflow-options {
  // These workflow options will be encrypted when stored in the database
  encrypted-fields: []

  // AES-256 key to use to encrypt the values in `encrypted-fields`
  base64-encryption-key: "AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA="

  // Directory where to write per workflow logs
  workflow-log-dir: "cromwell-workflow-logs"

  // When true, per workflow logs will be deleted after copying
  workflow-log-temporary: true

  // Workflow-failure-mode determines what happens to other calls when a call fails. Can be either ContinueWhilePossible or NoNewCalls.
  // Can also be overridden in workflow options. Defaults to NoNewCalls. Uncomment to change:
  //workflow-failure-mode: "ContinueWhilePossible"
}

// Optional call-caching configuration. Disabled by default.
call-caching {
  enabled = false

  // The Docker image specified in the 'runtime' section of a task can be used as-is
  // or Cromwell can lookup this Docker image to get a complete hash.  For example,
  // if a task specifies docker: "ubuntu:latest" and if lookup-docker-hash is true,
  // Then Cromwell would query DockerHub to resolve "ubuntu:latest" to something like
  // a2c950138e95bf603d919d0f74bec16a81d5cc1e3c3d574e8d5ed59795824f47
  //
  // A value of 'true' means that call hashes will more accurately represent the
  // Docker image that was used to run the call, but at a cost of having to make a
  // request to an external service (DockerHub, GCR).  If a call fails to lookup a
  // Docker hash, it will fail.
  lookup-docker-hash = false
}

server {
  // If 'true', a SIGINT will trigger Cromwell to attempt to abort all currently running jobs before exiting
  abortJobsOnTerminate = false
}

backend {
  default = "Local"
  providers = [
    {
      name = "Local"
      class = "cromwell.engine.backend.local.LocalBackend"
      config {
        // Root directory where Cromwell writes job results.  This directory must be
        // visible and writeable by the Cromwell process as well as the jobs that Cromwell
        // launches.
        root: "cromwell-executions"

        // Cromwell makes a link to your input files within <root>/<workflow UUID>/workflow-inputs
        // The following are strategies used to make those links.  They are ordered.  If one fails
        // The next one is tried:
        //
        // hard-link: attempt to create a hard-link to the file
        // copy: copy the file
        // soft-link: create a symbolic link to the file
        //
        // NOTE: soft-link will be skipped for Docker jobs
        localization: [
          "hard-link", "soft-link", "copy"
        ]
      }
    },
    {
      name = "SGE"
      class = "cromwell.engine.backend.sge.SgeBackend"
      config {
        // Root directory where Cromwell writes job results.  This directory must be
        // visible and writeable by the Cromwell process as well as the jobs that Cromwell
        // launches.
        root: "cromwell-executions"

        // Cromwell makes a link to your input files within <root>/<workflow UUID>/workflow-inputs
        // The following are strategies used to make those links.  They are ordered.  If one fails
        // The next one is tried:
        //
        // hard-link: attempt to create a hard-link to the file
        // copy: copy the file
        // soft-link: create a symbolic link to the file
        //
        // NOTE: soft-link will be skipped for Docker jobs
        localization: [
          "hard-link", "soft-link", "copy"
        ]
      }
    },
    {
      name = "JES"
      class = "cromwell.engine.backend.jes.JesBackend"
      config {
        // Google project
        project = "my-cromwell-workflows"

        // Base bucket for workflow executions
        baseExecutionBucket = "gs://my-cromwell-workflows-bucket"

        // Endpoint for APIs, no reason to change this unless directed by Google.
        endpointUrl = "https://genomics.googleapis.com/"

        // Polling for completion backs-off gradually for slower-running jobs.
        // This is the maximum polling interval (in seconds):
        maximumPollingInterval = 600

        applicationName = "cromwell"

        // Optional Dockerhub Credentials. Can be used to access private docker images.
        docker {
          // dockerAccount = ""
          // dockerToken = ""
        }

        // cromwellAuthenticationScheme can take the values "service_account",
        // "user_account", and "application_default". The first two are described
        // in the stanzas below.
        // Use "application_default" to use the default service account credentials.
        // This is useful if you are running on a GCE VM and if you don't need
        // user level access. See https://developers.google.com/identity/protocols/application-default-credentials
        // for more info. No further information is needed.
        cromwellAuthenticationScheme = "application_default"

        // If cromwellAuthenticationScheme is "service_account"
        serviceAuth {
          // pemFile = ""
          // serviceAccountId = ""
        }

        // If cromwellAuthenticationScheme is "user_account"
        userAuth {
          // user = ""
          // secretsFile = ""
          // dataStoreDir = ""
        }

        // [Optional]
        // Can be defined to provide an alternative way for Cromwell to perform some runtime interactions with GCS.
        // For instance data localization and delocalization in GoogleCloudStorage will be done on behalf of another entity (typically a user).
        // This allows cromwell to localize data that wouldn't be accessible using whatever "cromwellAuthenticationScheme" has been defined.
        // The currently only available scheme is refresh, which requires a refresh token to be passed upon every workflow submission (see "workflow options" in cromwell documentation).
        // In that scheme, a client_id and client_secrets must be provided. They must be the ones that have been used to generate the above-mentioned refresh token.
        // userAuthenticationScheme = "refresh"
        // refreshTokenAuth = {
        //   client_id = ""
        //   client_secret = ""
        // }
      }
    }
  ]
}

database {
  config = main.hsqldb

  main {
    hsqldb {
      db.url = "jdbc:hsqldb:mem:${slick.uniqueSchema};shutdown=false;hsqldb.tx=mvcc"
      db.driver = "org.hsqldb.jdbcDriver"
      db.connectionTimeout = 1000 // NOTE: 1000ms (the default) is ok for a small hsqldb, but often too short for mysql
      driver = "slick.driver.HsqldbDriver$"
    }
  }

  test {
    hsqldb {
      db.url = "jdbc:hsqldb:mem:testdb;shutdown=false;hsqldb.tx=mvcc"
      db.driver = "org.hsqldb.jdbcDriver"
      db.connectionTimeout = 1000 // NOTE: 1000ms (the default) is ok for a small hsqldb, but often too short for mysql
      driver = "slick.driver.HsqldbDriver$"
      liquibase = {
        changelog = "src/main/migrations/changelog.xml"
        connection = "liquibase.database.jvm.HsqlConnection"
      }
    }

    mysql {
      db.url = "jdbc:mysql://localhost/cromwell_test"
      db.user = "travis"
      db.password = ""
      db.driver = "com.mysql.jdbc.Driver"
      db.connectionTimeout = 5000 // NOTE: The default 1000ms is often too short for production mysql use
      driver = "slick.driver.MySQLDriver$"
      liquibase = {
        changelog = "src/main/migrations/changelog.xml"
      }
    }
  }
}


instrumentation {
  use-kamon = false
}

// Basic defaults for kamon configuration. There are a plethora of things which you can set, see the Kamon docs
// for more information. Note that at a minimum you'll need to fill in the "hostname" field below. Outside of hostname
// you should make sure you know what you're doing before overriding any of the rest of these
kamon {
  metric.filters {
    akka-dispatcher {
      includes = [ "**" ]
      excludes = [ ]
    }

    akka-actor {
      includes = [ "cromwell-system/user/**" ]
      excludes = [ "*/system/**", "*/user/IO-**", "*kamon*" ]
    }

    akka-router {
      includes = [ "**" ]
      excludes = []
    }
  }

  statsd {
    // If you're using Kamon instrumentation you'll want need to specify your hostname (and potentially port) where
    // your statsd is running. Remember that StatsD packets are sent using UDP and setting unreachable hosts and/or
    // not open ports wont be warned by the Kamon, your data wont go anywhere.
    //   hostname = "10.255.0.100"
    simple-metric-key-generator.application = "cromwell"
  }
}


