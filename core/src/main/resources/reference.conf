##################################
# Cromwell Reference Config File #
##################################

# This is the reference config file that contains all the default settings.
# The application config contains the default _override_ settings for cromwell.
# Make your edits/overrides in your cromwell.conf and be sure to `include required(classpath("application"))`.
# Add/See documented examples in cromwell.examples.conf.

webservice {
  port = 8000
  interface = 0.0.0.0
  binding-timeout = 5s
  instance.name = "reference"
}

akka {
  actor.default-dispatcher.fork-join-executor {
    # Number of threads = min(parallelism-factor * cpus, parallelism-max)
    # Below are the default values set by Akka, uncomment to tune these

    #parallelism-factor = 3.0
    #parallelism-max = 64
  }

  priority-mailbox {
    mailbox-type = "akka.dispatch.UnboundedControlAwareMailbox"
  }

  dispatchers {
    # A dispatcher for actors performing blocking io operations
    # Prevents the whole system from being slowed down when waiting for responses from external resources for instance
    io-dispatcher {
      type = Dispatcher
      executor = "fork-join-executor"
      # Using the forkjoin defaults, this can be tuned if we wish
    }

    # A dispatcher for actors handling API operations
    # Keeps the API responsive regardless of the load of workflows being run
    api-dispatcher {
      type = Dispatcher
      executor = "fork-join-executor"
    }

    # A dispatcher for engine actors
    # Because backends behavior is unpredictable (potentially blocking, slow) the engine runs
    # on its own dispatcher to prevent backends from affecting its performance.
    engine-dispatcher {
      type = Dispatcher
      executor = "fork-join-executor"
    }

    # A dispatcher used by supported backend actors
    backend-dispatcher {
      type = Dispatcher
      executor = "fork-join-executor"
    }

    # A dispatcher used for the service registry
    service-dispatcher {
      type = Dispatcher
      executor = "fork-join-executor"
    }

    # A dispatcher to bulkhead the health monitor from the rest of the system. Sets throughput low in order to
    # ensure the monitor is fairly low priority
    health-monitor-dispatcher {
      type = Dispatcher
      executor = "thread-pool-executor"
      thread-pool-executor {
        fixed-pool-size = 4
      }

      throughput = 1
    }
    # Note that without further configuration, all other actors run on the default dispatcher
  }

  coordinated-shutdown.phases {
    abort-all-workflows {
      # This phase is used to give time to Cromwell to abort all workflows upon shutdown.
      # It's only used if system.abort-jobs-on-terminate = true
      # This timeout can be adjusted to give more or less time to Cromwell to abort workflows
      timeout = 1 hour
      depends-on = [service-unbind]
    }

    stop-io-activity{
      # Adjust this timeout according to the maximum amount of time Cromwell
      # should be allowed to spend flushing its database queues
      timeout = 30 minutes
      depends-on = [service-stop]
    }
  }
}

system {
  # If 'true', a SIGINT will trigger Cromwell to attempt to abort all currently running jobs before exiting
  # Defaults to false in server mode, and true in run mode.
  # abort-jobs-on-terminate = false

  # If 'true', a SIGTERM or SIGINT will trigger Cromwell to attempt to gracefully shutdown in server mode,
  # in particular clearing up all queued database writes before letting the JVM shut down.
  # The shutdown is a multi-phase process, each phase having its own configurable timeout. See the Dev Wiki for more details.
  graceful-server-shutdown = true

  # If 'true' then when Cromwell starts up, it tries to restart incomplete workflows
  workflow-restart = true

  # Cromwell will cap the number of running workflows at N
  max-concurrent-workflows = 5000

  # Cromwell will launch up to N submitted workflows at a time, regardless of how many open workflow slots exist
  max-workflow-launch-count = 50

  # Number of seconds between workflow launches
  new-workflow-poll-rate = 20

  # Since the WorkflowLogCopyRouter is initialized in code, this is the number of workers
  number-of-workflow-log-copy-workers = 10

  # Default number of cache read workers
  number-of-cache-read-workers = 25

  # Maximum scatter width per scatter node. Cromwell will fail the workflow if the scatter width goes beyond N
  max-scatter-width-per-scatter = 1000000

  # Total max. jobs that can be created per root workflow. If it goes beyond N, Cromwell will fail the workflow by:
  # - no longer creating new jobs
  # - let the jobs that have already been started finish, and then fail the workflow
  total-max-jobs-per-root-workflow = 1000000

  io {
    # Global Throttling - This is mostly useful for GCS and can be adjusted to match
    # the quota availble on the GCS API
    number-of-requests = 100000
    per = 100 seconds

    # Number of times an I/O operation should be attempted before giving up and failing it.
    number-of-attempts = 5
    
    # Amount of time after which an I/O operation will timeout if no response has been received.
    # Note that a timeout may result in a workflow failure so be careful not to set a timeout too low.
    # Unless you start experiencing timeouts under very heavy load there should be no reason to change the default values.
    timeout {
      default = 3 minutes
      # Copy can be a time consuming operation and its timeout can be set separately.
      copy = 1 hour
    }
    
    gcs {
      parallelism = 10
    }
    
    nio {
      parallellism = 10
    }
  }

  # Maximum number of input file bytes allowed in order to read each type. 
  # If exceeded a FileSizeTooBig exception will be thrown.
  input-read-limits {

    lines = 128000

    bool = 7

    int = 19

    float = 50

    string = 128000

    json = 128000

    tsv = 128000

    map = 128000

    object = 128000
  }

  # Rate at which Cromwell updates its instrumentation gauge metrics (e.g: Number of workflows running, queued, etc..)
  instrumentation-rate = 5 seconds
  
  job-rate-control {
    jobs = 50
    per = 1 second
  }

  workflow-heartbeats {
    heartbeat-interval: 2 minutes
    ttl: 10 minutes
    write-batch-size: 10000
    write-threshold: 10000
  }

  job-shell: "/bin/bash"
}

workflow-options {
  # These workflow options will be encrypted when stored in the database
  encrypted-fields: []

  # AES-256 key to use to encrypt the values in `encrypted-fields`
  base64-encryption-key: "AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA="

  # Directory where to write per workflow logs
  workflow-log-dir: "cromwell-workflow-logs"

  # When true, per workflow logs will be deleted after copying
  workflow-log-temporary: true

  # Workflow-failure-mode determines what happens to other calls when a call fails. Can be either ContinueWhilePossible or NoNewCalls.
  # Can also be overridden in workflow options. Defaults to NoNewCalls. Uncomment to change:
  #workflow-failure-mode: "ContinueWhilePossible"
}

# Optional call-caching configuration.
call-caching {
  # Allows re-use of existing results for jobs you've already run
  # (default: false)
  enabled = false

  # Whether to invalidate a cache result forever if we cannot reuse them. Disable this if you expect some cache copies
  # to fail for external reasons which should not invalidate the cache (e.g. auth differences between users):
  # (default: true)
  invalidate-bad-cache-results = true
}

google {

  application-name = "cromwell"

  # See other auths examples in cromwell.examples.conf
  auths = [
    {
      name = "application-default"
      scheme = "application_default"
    }
  ]
}
# Filesystems available in this Crowmell instance
# They can be enabled individually in the engine.filesystems stanza and in the config.filesystems stanza of backends
# There is a default built-in local filesytem that can also be referenced as "local" as well.
filesystems {
  demo-dos {
    class = "cromwell.filesystems.demo.dos.DemoDosPathBuilderFactory"
  }
  gcs {
    class = "cromwell.filesystems.gcs.GcsPathBuilderFactory"
  }
  oss {
    class = "cromwell.filesystems.oss.OssPathBuilderFactory"
  }
  s3 {
    class = "cromwell.filesystems.s3.S3PathBuilderFactory"
  }
  http {
    class = "cromwell.filesystems.http.HttpPathBuilderFactory"
  }
}

docker {
  hash-lookup {
    // /!\ Attention /!\
    // If you disable this call caching will be disabled for jobs with floating docker tags !
    enabled = true
    // Set this to match your available quota against the Google Container Engine API
    gcr-api-queries-per-100-seconds = 1000
    // Time in minutes before an entry expires from the docker hashes cache and needs to be fetched again
    cache-entry-ttl = "20 minutes"
    // Maximum number of elements to be kept in the cache. If the limit is reached, old elements will be removed from the cache
    cache-size = 200
    // How should docker hashes be looked up. Possible values are "local" and "remote"
    // "local": Lookup hashes on the local docker daemon using the cli
    // "remote": Lookup hashes on docker hub and gcr
    method = "remote"
  }
}

engine {
  # This instructs the engine which filesystems are at its disposal to perform any IO operation that it might need.
  # For instance, WDL variables declared at the Workflow level will be evaluated using the filesystems declared here.
  # If you intend to be able to run workflows with this kind of declarations:
  # workflow {
  #    String str = read_string("gs://bucket/my-file.txt")
  # }
  # You will need to provide the engine with a gcs filesystem
  # Note that the default filesystem (local) is always available.
  filesystems {
    local {
      enabled: true
    }
  }
}

languages {
  default: WDL
  WDL {
    versions {
      default: "draft-2"
      "draft-2" {
        language-factory = "languages.wdl.draft2.WdlDraft2LanguageFactory"
        config {
          strict-validation: false
          enabled: true
        }
      }
      "1.0" {
        # WDL draft-3 was our in-progress name for what became WDL 1.0
        language-factory = "languages.wdl.draft3.WdlDraft3LanguageFactory"
        config {
          strict-validation: true
          enabled: true
        }
      }
      "biscayne" {
        # WDL biscayne is our in-progress name for what will (probably) become WDL 1.1
        language-factory = "languages.wdl.biscayne.WdlBiscayneLanguageFactory"
        config {
          strict-validation: true
          enabled: true
        }
      }
    }
  }
  CWL {
    versions {
      default: "v1.0"
      "v1.0" {
        language-factory = "languages.cwl.CwlV1_0LanguageFactory"
        config {
          strict-validation: false
          enabled: true
        }
      }
    }
  }
}


# Other backend examples are in cromwell.examples.conf
backend {
  default = "Local"
  providers {
    Local {
      actor-factory = "cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory"
      config {
        include required(classpath("reference_local_provider_config.inc.conf"))
      }
    }

  }
}

services {
  KeyValue {
    class = "cromwell.services.keyvalue.impl.SqlKeyValueServiceActor"
    config {
      # Similar to metadata service config, see cromwell.examples.conf
      # db-batch-size = 200
      # db-flush-rate = 5 seconds
    }
  }
  MetadataService {
    class = "cromwell.services.metadata.impl.MetadataServiceActor"
    config {
      # See cromwell.examples.conf for details on settings one can use here as they depend on the implementation
      # being used.
    }
  }
  Instrumentation {
    # Default noop service - instrumentation metrics are ignored
    class = "cromwell.services.instrumentation.impl.noop.NoopInstrumentationServiceActor"
  }
  HealthMonitor {
    class = "cromwell.services.healthmonitor.impl.standard.StandardHealthMonitorServiceActor"
    # Override the standard dispatcher. In particular this one has a low throughput so as to be lower in priority
    dispatcher = "akka.dispatchers.health-monitor-dispatcher"
  }
  LoadController {
    class = "cromwell.services.loadcontroller.impl.LoadControllerServiceActor"
    config {
      # See cromwell.examples.conf for details on settings one can use here
    }
  }
}

database {
  # hsql default
  profile = "slick.jdbc.HsqldbProfile$"

  # see all possible parameters and default values here:
  # http://slick.lightbend.com/doc/3.2.0/api/index.html#slick.jdbc.JdbcBackend$DatabaseFactoryDef@forConfig(String,Config,Driver):Database
  db {
    driver = "org.hsqldb.jdbcDriver"
    url = "jdbc:hsqldb:mem:${uniqueSchema};shutdown=false;hsqldb.tx=mvcc"
    connectionTimeout = 3000
  }

  migration {
    # For databases with a very large number of symbols, selecting all the rows at once can generate a variety of
    # problems. In order to avoid any issue, the selection is paginated. This value sets how many rows should be
    # retrieved and processed at a time, before asking for the next chunk.
    read-batch-size = 100000

    # Because a symbol row can contain any arbitrary wdl value, the amount of metadata rows to insert from a single
    # symbol row can vary from 1 to several thousands (or more). To keep the size of the insert batch from growing out
    # of control we monitor its size and execute/commit when it reaches or exceeds writeBatchSize.
    write-batch-size = 100000
  }
}

# Configuration for load-control related values 
load-control {
  ## Queue Size Thresholds ##
  # Cromwell centralizes some operations through singleton actors (possibly acting as routers).
  # This allows for a more efficient control, throttling, and potentially batching of those operations which overall improves throughput.
  # In order to do that, those operations are queued until they can be performed.
  # Those queues are for the most part unbounded in size, which can become a problem under heavy load.
  # Each actor can however let the load controller service know when it considers its work load to be abnormally high.
  # In the case of those queuing actors, this means that their queue size is over a certain threshold.
  # This section allows to configure those threshold values.
  # They should be kept at a reasonable number where reasonable will depend on your system and how much load Cromwell is submitted to.
  # If they're too high they could end up using a lot of memory, if they're too small any small spike will be considered a high load and the system will automatically slow itself down.
  # Benchmarking is recommended to find the values that suit your use case best.
  # If you use the statsD instrumentation service, the queue size and throughput of these actors are instrumented and looking at their value over time can also help you find the right configuration.
  
  job-store-read = 10000
  job-store-write = 10000
  # call cache read actors are routed (several actors are performing cache read operations
  # this threshold applies to each routee individually, so set it to a lower value to account for that
  # to change the number of routees, see the services.number-of-cache-read-workers config value
  call-cache-read = 1000
  call-cache-write = 10000
  key-value-read = 10000
  key-value-write = 10000
  # The I/O queue has the specificity to be bounded. This sets its size
  io-queue-size = 10000
  # If the I/O queue is full, subsequent requests are rejected and to be retried later.
  # This time window specifies how much time without request rejection consititutes a "back to normal load" event
  io-normal-window = 10000
  # metadata is an order of magnitude higher because its normal load is much higher than other actors
  metadata-write = 100000
  
  ## Backend specific ##
  # Google requests to the Pipelines API are also queued and batched
  papi-requests = 10000
  
  ## Misc. ##
  # How often each actor should update its perceived load
  monitoring-frequency = 5 seconds
}
